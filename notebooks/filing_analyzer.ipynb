{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo's:\n",
    "\n",
    "- Remove sentence limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import yaml\n",
    "import hashlib\n",
    "\n",
    "from financial_report_analyzer.database_conntector import DatabaseConnector\n",
    "from financial_report_analyzer.scraping import SECScraper\n",
    "from financial_report_analyzer.model import ScoringModel\n",
    "from financial_report_analyzer.content_extractor import TextExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = nasdaq.applymap(lambda x: x.replace(\".\",\"\").replace(\",\", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_tickers = {}\n",
    "for _, row in nasdaq.iterrows():\n",
    "    nasdaq_tickers[row[\"Symbol\"]] = {\n",
    "        \"name\": row[\"Name\"],\n",
    "        \"market_cap\": row[\"Market Cap\"],\n",
    "        \"last_sale\": row[\"Last Sale\"],\n",
    "        \"date\": datetime.now().date()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../financial_report_analyzer/defaults/nasdaq_tickers.yaml\", \"w\") as f:\n",
    "    yaml.dump(nasdaq_tickers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = SECScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = scraper.request_archive(\"ADBE\")\n",
    "archive_urls = scraper.fetch_filing_urls(archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_url = archive_urls[2024][\"filings_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_response = scraper.request_filings(filing_url)\n",
    "archive_soup = BeautifulSoup(filings_response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(archive.text, \"html.parser\")\n",
    "table = soup.find(\"table\", class_=\"tableFile2\")\n",
    "rows = table.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = ['Description', 'Document']\n",
    "\n",
    "i = 0\n",
    "cell_dict = {}\n",
    "# Extract data from each row\n",
    "for row in rows[1:4]:  # Skipping the header row\n",
    "    cells = row.find_all('td')\n",
    "    cell_dict[i] = cells\n",
    "    data.append([cells[0].text.strip(), cells[1].find(\"a\")[\"href\"]])\n",
    "    i += 1\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[1:]:\n",
    "    url = row.find(\"a\")[\"href\"]\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash(texts: list):\n",
    "    raw_text = \"\".join(texts)\n",
    "    return hashlib.sha256(raw_text.encode()).hexdigest()\n",
    "\n",
    "def merged(df, col1=\"ticker\", col2=\"year\"):\n",
    "    return df[col1] + df[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_scraper = SECScraper()\n",
    "model = ScoringModel()\n",
    "connector = DatabaseConnector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.table_names\n",
    "\n",
    "filings = connector.fetch_data(\"sec_filings\").set_index(\"id\")\n",
    "# scores = connector.fetch_data(\"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filing_url(filings, ticker, year):\n",
    "    year = str(year)\n",
    "    ticker = str(ticker)\n",
    "    return filings.query(\"ticker==@ticker & year==@year\")[\"filing_url\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_url = filings.pipe(get_filing_url, \"AAPL\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = sec_scraper.fetch_report(filing_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(report.content, parser=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/aapl_2023.xml', 'w') as file:\n",
    "    file.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arelle import Cntlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbrl = Cntlr.Cntlr().modelManager.load(filing_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factData = pd.DataFrame(data=[(fact.concept.qname,\n",
    "                           fact.value,\n",
    "                           fact.isNumeric,\n",
    "                           fact.contextID,\n",
    "                           fact.context.startDatetime,\n",
    "                           fact.context.endDatetime) for fact in xbrl.facts], columns=[\"qname\", \"value\", \"isnumeric\", \"context_id\", \"start_date\", \"end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factData[\"qname_type\"] = factData[\"qname\"].apply(lambda x: str(x).split(\":\")[0])\n",
    "factData[\"name\"] = factData[\"qname\"].apply(lambda x: str(x).split(\":\")[1])\n",
    "factData = factData.drop(\"qname\", axis=1)\n",
    "factData = factData.set_index(\"name\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factData.query(\"qname_type=='us-gaap' & isnumeric==False\")[\"value\"].iloc[12]#.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factData.query(\"qname_type=='us-gaap' & isnumeric==False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sendtb = factData.query(\"name=='StockholdersEquityNoteDisclosureTextBlock'\")[\"value\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(sendtb, parser=\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', string='Share Repurchase Program').find_next_sibling('div').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find('p').text\n",
    "print(f\"Title: {title}\")\n",
    "\n",
    "# Extract information about the Share Repurchase Program\n",
    "share_repurchase_program_info = soup.find('div', text='Share Repurchase Program').find_next_sibling('div').text.strip()\n",
    "print(f\"Share Repurchase Program Information: {share_repurchase_program_info}\")\n",
    "\n",
    "# Assuming you want to extract table data, find the table and iterate over its rows\n",
    "table = soup.find('table')\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Extracting headers (assuming the first row contains headers)\n",
    "headers = [th.text.strip() for th in rows[0].find_all('td')]\n",
    "\n",
    "# Extracting each row data\n",
    "for row in rows[1:]:\n",
    "    cells = [td.text.strip() for td in row.find_all('td')]\n",
    "    row_data = dict(zip(headers, cells))\n",
    "    print(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fact in xbrl.facts:\n",
    "    print(fact.qname, fact.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = report.text\n",
    "\n",
    "# Define the regular expression pattern to match item headers\n",
    "pattern = r'<a name=\"ITEM[^\"]*\"[^>]*>(.*?)</a>'\n",
    "\n",
    "# Extract item headers using regular expressions\n",
    "item_headers = re.findall(pattern, html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_headers = soup.find_all('a', attrs={'name': lambda x: x and 'ITEM' in x})\n",
    "\n",
    "# Extract the text from the item headers\n",
    "item_headers_text = [item_header.get_text() for item_header in item_headers]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed = (filings.pipe(merged)).isin((scores.pipe(merged)).tolist())\n",
    "\n",
    "analyzed_filings = filings[analyzed]\n",
    "not_analyzed_filings = filings[~analyzed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report_scores(filing, sentences_limit=False):\n",
    "    ticker = filing[\"ticker\"]\n",
    "    year = filing[\"year\"]\n",
    "    filing_url = filing[\"filing_url\"]\n",
    "\n",
    "    report = sec_scraper.fetch_report(filing_url)\n",
    "\n",
    "    extractor = TextExtractor(report)\n",
    "    sentences = extractor.get_sentences()\n",
    "    text_hash = create_hash(sentences)\n",
    "\n",
    "    if sentences_limit:\n",
    "        sentences = sentences[:50]\n",
    "    \n",
    "    report_scores = model.calculate_report_scores(\n",
    "        sentences[:50]\n",
    "    )\n",
    "    report_scores.update(\n",
    "        {\n",
    "            \"ticker\": ticker,\n",
    "            \"year\": year,\n",
    "            \"analysis_timestamp\": datetime.now(),\n",
    "            \"text_hash\": text_hash,\n",
    "        }\n",
    "    )\n",
    "    return report_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_report_scores = []\n",
    "\n",
    "for _, filing in not_analyzed_filings.iterrows():\n",
    "    report_scores = create_report_scores(filing, sentences_limit=True)\n",
    "    new_report_scores.append(report_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store scores in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_scores = pd.concat([scores, pd.DataFrame(new_report_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.store_data(upload_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial-report-analyzer",
   "language": "python",
   "name": "financial-report-analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
